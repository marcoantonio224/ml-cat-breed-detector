{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3727e862-bcf1-41dd-a858-278fb28768b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: matplotlib in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: filelock in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# First download packages required\n",
    "pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73e90ff7-3994-4a87-854f-443d99e28fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Find cat breed dataset\n",
    "cat_dataset_train = \"./cat_dataset/train\"\n",
    "cat_dataset_test = \"./cat_dataset/test\"\n",
    "\n",
    "\n",
    "# Create a transforms pipeline manually (required for torchvision < 0.13)\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create Datasets\n",
    "train_data = datasets.ImageFolder(cat_dataset_train, transform=manual_transforms)\n",
    "test_data = datasets.ImageFolder(cat_dataset_test, transform=manual_transforms)\n",
    "breed_names = train_data.classes\n",
    "\n",
    "# Create Train DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=32, \n",
    "    shuffle=True,\n",
    "    num_workers=os.cpu_count(),\n",
    "    pin_memory=True\n",
    ")\n",
    "# Create Test DataLoader\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, \n",
    "    batch_size=32, \n",
    "    shuffle=True,\n",
    "    num_workers=os.cpu_count(),\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Create ResNet model\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(breed_names))\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d735731-2795-4f19-b0f0-7a8f968c3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cat_breed_detector_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_val_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        description = f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "        for images, labels in tqdm(train_loader, desc=description):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        \n",
    "        # Validate model and save the one with best accuracy\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        val_accuracy = val_correct / val_total\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        # Save the model if it performs better\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), \"cat_breed_detector_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2eb5dbea-3ee9-4475-82f6-81d11caf169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 226/226 [22:07<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.4918, Train Accuracy: 0.8391, Validation Accuracy: 0.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 226/226 [22:42<00:00,  6.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.2985, Train Accuracy: 0.9050, Validation Accuracy: 0.4599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 226/226 [18:25<00:00,  4.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.1514, Train Accuracy: 0.9573, Validation Accuracy: 0.4616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 226/226 [18:45<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.1697, Train Accuracy: 0.9465, Validation Accuracy: 0.4205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 226/226 [20:19<00:00,  5.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.2689, Train Accuracy: 0.9129, Validation Accuracy: 0.3956\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_cat_breed_detector_model(model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746a1e6-f22f-461b-99d7-13402751cb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
